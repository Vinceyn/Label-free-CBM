{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e3f3f5-a045-4d70-96f9-39b0384115da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gridsan/vyuan/.local/lib/python3.9/site-packages/')\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b345c118-d983-4234-bc85-f11e41c31485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_utils\n",
    "from utils import conceptset_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe0c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root = Path.cwd().parent.parent\n",
    "\n",
    "import os\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f569c19e-d3b1-428d-a8e5-64e71fd5391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ConceptNet params:\n",
    "LIMIT:how many relations to look up, higher limit -> larger concept set\n",
    "RELATIONS: which relations to include in search \n",
    "\n",
    "filters:\n",
    "CLASS_SIM_CUTOFF: Concenpts with cos similarity higher than this to any class will be removed\n",
    "OTHER_SIM_CUTOFF: Concenpts with cos similarity higher than this to another concept will be removed\n",
    "MAX_LEN: max number of characters in a concept\n",
    "\n",
    "PRINT_PROB: what percentage of filtered concepts will be printed\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LIMIT = 200\n",
    "RELATIONS = [\"HasA\", \"IsA\", \"PartOf\", \"HasProperty\", \"MadeOf\"]#, \"AtLocation\"]\n",
    "\n",
    "CLASS_SIM_CUTOFF = 0.85\n",
    "OTHER_SIM_CUTOFF = 0.9 \n",
    "MAX_LEN = 30\n",
    "\n",
    "PRINT_PROB = 0.2\n",
    "\n",
    "dataset = \"doctor_nurse\"\n",
    "save_name = 'data/concept_sets/conceptnet/conceptnet_{}_filtered_new.txt'.format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bb1903-e514-48ed-9449-c3f1a5239881",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_file = data_utils.LABEL_FILES[dataset]\n",
    "\n",
    "with open(cls_file, 'r') as f:\n",
    "    classes = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ea6f9-d084-42c7-a09f-a45cb2359849",
   "metadata": {},
   "source": [
    "# Collect initial concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d0c02f-bf5b-44d9-aa58-5e1c76b1c278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "concepts = conceptset_utils.get_init_conceptnet(classes, LIMIT, RELATIONS)\n",
    "# Store the concept in a file, to use it with the GPU kernel\n",
    "with open(save_name, 'w') as f:\n",
    "    for concept in concepts:\n",
    "        f.write(concept + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f17bbfef-1a85-4d94-9319-c1d2af8b0af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "# Load the concepts from save_name in the variable concepts\n",
    "with open(save_name, 'r') as f:\n",
    "    concepts = f.read().split('\\n')\n",
    "\n",
    "concepts = conceptset_utils.remove_too_long(concepts, MAX_LEN, PRINT_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59600ce4-67e6-4dc7-835f-98250048a697",
   "metadata": {},
   "source": [
    "# Filter out concepts too similar to class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913874cf-2000-4de7-9108-1dd4a7a1b520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Class:nurse - Deleting nurse\n",
      "4\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m concepts \u001b[39m=\u001b[39m conceptset_utils\u001b[39m.\u001b[39;49mfilter_too_similar_to_cls(concepts, classes, CLASS_SIM_CUTOFF, print_prob\u001b[39m=\u001b[39;49mPRINT_PROB)\n",
      "File \u001b[0;32m~/Label-free-CBM/label_free_cbm/notebooks/../src/utils/conceptset_utils.py:87\u001b[0m, in \u001b[0;36mfilter_too_similar_to_cls\u001b[0;34m(concepts, classes, sim_cutoff, device, print_prob)\u001b[0m\n\u001b[1;32m     85\u001b[0m concept_features_m \u001b[39m=\u001b[39m mpnet_model\u001b[39m.\u001b[39mencode(concepts)\n\u001b[1;32m     86\u001b[0m dot_prods_m \u001b[39m=\u001b[39m class_features_m \u001b[39m@\u001b[39m concept_features_m\u001b[39m.\u001b[39mT\n\u001b[0;32m---> 87\u001b[0m dot_prods_c \u001b[39m=\u001b[39m _clip_dot_prods(classes, concepts)\n\u001b[1;32m     88\u001b[0m \u001b[39m#weighted since mpnet has highger variance\u001b[39;00m\n\u001b[1;32m     89\u001b[0m dot_prods \u001b[39m=\u001b[39m (dot_prods_m \u001b[39m+\u001b[39m \u001b[39m3\u001b[39m\u001b[39m*\u001b[39mdot_prods_c)\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m\n",
      "File \u001b[0;32m~/Label-free-CBM/label_free_cbm/notebooks/../src/utils/conceptset_utils.py:145\u001b[0m, in \u001b[0;36m_clip_dot_prods\u001b[0;34m(list1, list2, device, clip_name, batch_size)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_clip_dot_prods\u001b[39m(list1, list2, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m, clip_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mViT-B/16\u001b[39m\u001b[39m\"\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m):\n\u001b[1;32m    144\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mReturns: numpy array with dot products\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 145\u001b[0m     clip_model, _ \u001b[39m=\u001b[39m clip\u001b[39m.\u001b[39;49mload(clip_name, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    146\u001b[0m     text1 \u001b[39m=\u001b[39m clip\u001b[39m.\u001b[39mtokenize(list1)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    147\u001b[0m     text2 \u001b[39m=\u001b[39m clip\u001b[39m.\u001b[39mtokenize(list2)\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Label-free-CBM/label_free_cbm/notebooks/../src/clip/clip.py:157\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, device, jit, download_root)\u001b[0m\n\u001b[1;32m    154\u001b[0m         state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(opened_file, map_location\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m jit:\n\u001b[0;32m--> 157\u001b[0m     model \u001b[39m=\u001b[39m build_model(state_dict \u001b[39mor\u001b[39;49;00m model\u001b[39m.\u001b[39;49mstate_dict())\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(device) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    159\u001b[0m         model\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[0;32m/state/partition1/llgrid/pkg/anaconda/anaconda3-2023a/lib/python3.9/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "concepts = conceptset_utils.filter_too_similar_to_cls(concepts, classes, CLASS_SIM_CUTOFF, print_prob=PRINT_PROB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c398239-e2c8-42a0-aaf7-93810c389a72",
   "metadata": {},
   "source": [
    "# Filter out concepts too similar to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee717e-066e-4916-a30a-dbb0c7df688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = conceptset_utils.filter_too_similar(concepts, OTHER_SIM_CUTOFF, print_prob=PRINT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061eca82-5705-4839-a6cd-b9eef0b3d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_name, \"w\") as f:\n",
    "    f.write(concepts[0])\n",
    "    for concept in concepts[1:]:\n",
    "        f.write(\"\\n\" + concept)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
